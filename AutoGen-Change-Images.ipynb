{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Helpful guide from AutoGen: https://github.com/microsoft/autogen/blob/main/notebook/agentchat_lmm_gpt-4v.ipynb\n",
    "- And the blog post: https://microsoft.github.io/autogen/blog/2023/11/06/LMM-Agent/\n",
    "- From AI Jason: https://github.com/JayZeeDesign/vision-agent-with-llava/blob/main/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import autogen\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-1106-preview\", \"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "gpt4_llm_config = {\"config_list\": config_list_gpt4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe an Image\n",
    "\n",
    "Requires installing the `Pillow` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "What's on the image? \n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "The image shows an adorable, stylized cartoon rabbit with large, expressive eyes and a playful smile. The rabbit has soft-looking fur, large ears, and is depicted in mid-leap against a vibrant, colorful background that suggests a serene, grassy meadow during sunrise or sunset. The sky is filled with warm colors and a few birds can be seen in the distance. There are also some flowers and plants in the foreground, adding to the peaceful and cheerful setting of the image.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "image_agent = MultimodalConversableAgent(\n",
    "    name=\"image-explainer\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config={\"config_list\": config_list_4v, \"temperature\": 0.5, \"max_tokens\": 300}\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"NEVER\", # Try between ALWAYS or NEVER\n",
    "    max_consecutive_auto_reply=0\n",
    ")\n",
    "\n",
    "# Ask the question with an image\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"What's on the image? \n",
    "<img images/RabbitCartoonHD.png>.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "Which image will be more appealing to a 3yo child? Why?\n",
      "<image>                          \n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "The second image, which features a cute, cartoon-style bunny in a colorful and whimsical setting, would likely be more appealing to a 3-year-old child. Young children are often attracted to bright colors, simple shapes, and friendly, anthropomorphic animal characters that are common in children's media. The bunny's exaggerated features, such as large eyes and a cheerful expression, are designed to be engaging and endearing to young viewers.\n",
      "\n",
      "The first image, which depicts a highly detailed and realistic robot holding a smartphone, might not be as immediately appealing to a very young child. The complexity and mechanical nature of the robot, along with the cooler color palette, may not capture a toddler's interest as effectively as the warm, inviting scene of the cartoon bunny.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ask the question with an image\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"Which image will be more appealing to a 3yo child? Why?\n",
    "<img images/AIRobot.jpeg>                          \n",
    "<img images/RabbitCartoonHD.png>.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "What's the facial expression of the person on the image? WHat can you tell about the person?\n",
      "<image>.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "The person in the image is smiling and appears to be in a positive or happy mood. His arms are crossed, which can sometimes indicate confidence or self-assurance. He is wearing a light blue, button-up shirt, which suggests a business casual or professional dress code. The background is black, indicating that the photo might have been taken in a studio setting or edited to have a plain background, which is common for professional headshots or promotional materials.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ask the question with an image\n",
    "user_proxy.initiate_chat(image_agent, \n",
    "                         message=\"\"\"What's the facial expression of the person on the image? WHat can you tell about the person?\n",
    "<img images/KO.png>.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Images with DALL-E 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def generate_image(prompt):\n",
    "    print(\"Calling the function with DALL-E 3\")\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"{prompt}\",\n",
    "        size=\"1024x1024\",\n",
    "        style=\"vivid\",\n",
    "        n=1,\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    print(image_url)\n",
    "    return f\"<img {image_url}>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calling for dalle assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create llm config\n",
    "llm_config_dalle = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"generate_image\",\n",
    "            \"description\": \"Use DALL-E 3 model to generate image based on a prompt, return the URL of the generated image\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"a descriptive prompt that describes the image in detail\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"prompt\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    # \"request_timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "image_agent = MultimodalConversableAgent(\n",
    "    name=\"image-explainer\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config={\"config_list\": config_list_4v, \"temperature\": 0.5, \"max_tokens\": 300}\n",
    ")\n",
    "\n",
    "# Create assistant agent\n",
    "img_gen_assistant = AssistantAgent(\n",
    "    name=\"text_to_img_prompt_expert\",\n",
    "    system_message=\"\"\"You are a text to image AI model expert, \n",
    "    you will use generate_image function to generate image with prompt provided.\n",
    "    Then you return the generated image to the img_critic.\n",
    "    Then, you improve prompt based on feedback provided from img_critic until it is 10/10.\"\"\",\n",
    "    llm_config=llm_config_dalle,\n",
    "    function_map={\n",
    "        \"generate_image\": generate_image,\n",
    "    },\n",
    ")\n",
    "\n",
    "img_critic_assistant = MultimodalConversableAgent(\n",
    "    name=\"img_critic\",\n",
    "    system_message=\"\"\"You are an AI image critique, you will review the image created with generate_image.\n",
    "     You will rate the image in scale 1-10 based on 2 criteria:\n",
    "     1. Does the image meet the initial requirement of the user?\n",
    "     2. Is the image suitable for 3yo kids.\n",
    "     You will provide feedback on how to improve the prompt to perfectly match both criteria.\"\"\",\n",
    "    llm_config={\"config_list\": config_list_4v},\n",
    "    # function_map={\n",
    "    #     \"generate_image\": generate_image,\n",
    "    # },\n",
    ")\n",
    "\n",
    "# Create user proxy agent\n",
    "admin = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "# Create groupchat\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, img_gen_assistant, img_critic_assistant],\n",
    "    messages=[],\n",
    "    max_round=5,\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Generate an image of a baby sheep.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mtext_to_img_prompt_expert\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: generate_image *****\u001b[0m\n",
      "Arguments: \n",
      "{\"prompt\":\"baby sheep\"}\n",
      "\u001b[32m***************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION generate_image...\u001b[0m\n",
      "Calling the function with DALL-E 3\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-Xzj1yaisXt5cDNveMyg1I7wI/user-9YZozn3HQ3tv70cLgw6ILiKX/img-H1w8mHfURFgTyiMud67nFT0H.png?st=2023-11-09T10%3A40%3A35Z&se=2023-11-09T12%3A40%3A35Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-09T06%3A21%3A48Z&ske=2023-11-10T06%3A21%3A48Z&sks=b&skv=2021-08-06&sig=w%2BTBxMyJ%2B/HZzgxxQDcqPp7APg9Vy5Z%2BBTjo%2BeJXDEE%3D\n",
      "\u001b[33mtext_to_img_prompt_expert\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"generate_image\" *****\u001b[0m\n",
      "<img https://oaidalleapiprodscus.blob.core.windows.net/private/org-Xzj1yaisXt5cDNveMyg1I7wI/user-9YZozn3HQ3tv70cLgw6ILiKX/img-H1w8mHfURFgTyiMud67nFT0H.png?st=2023-11-09T10%3A40%3A35Z&se=2023-11-09T12%3A40%3A35Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-09T06%3A21%3A48Z&ske=2023-11-10T06%3A21%3A48Z&sks=b&skv=2021-08-06&sig=w%2BTBxMyJ%2B/HZzgxxQDcqPp7APg9Vy5Z%2BBTjo%2BeJXDEE%3D>\n",
      "\u001b[32m***********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kris/dev/ag-tutorials/AutoGen-Change-Images.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kris/dev/ag-tutorials/AutoGen-Change-Images.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(manager, message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGenerate an image of a baby sheep.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:540\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \n\u001b[1;32m    528\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 540\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:340\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    338\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 340\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    343\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:471\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    472\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    473\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:883\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 883\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    884\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    885\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/groupchat.py:169\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    167\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39mselect_speaker(speaker, \u001b[39mself\u001b[39m)\n\u001b[1;32m    168\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[39m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m groupchat\u001b[39m.\u001b[39madmin_name \u001b[39min\u001b[39;00m groupchat\u001b[39m.\u001b[39magent_names:\n\u001b[1;32m    173\u001b[0m         \u001b[39m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:883\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 883\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    884\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    885\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:731\u001b[0m, in \u001b[0;36mConversableAgent.check_termination_and_human_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[39m# if the human input is empty, and the message is a termination message, then we will terminate the conversation\u001b[39;00m\n\u001b[1;32m    730\u001b[0m         reply \u001b[39m=\u001b[39m reply \u001b[39mif\u001b[39;00m reply \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m terminate \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mexit\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 731\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_termination_msg(message):\n\u001b[1;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuman_input_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNEVER\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    733\u001b[0m         reply \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mexit\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/contrib/multimodal_conversable_agent.py:49\u001b[0m, in \u001b[0;36mMultimodalConversableAgent.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     38\u001b[0m     name,\n\u001b[1;32m     39\u001b[0m     system_message,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_system_message(system_message)\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_termination_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     47\u001b[0m     is_termination_msg\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m is_termination_msg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     \u001b[39melse\u001b[39;00m (\u001b[39mlambda\u001b[39;00m x: \u001b[39many\u001b[39m([item[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTERMINATE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m item[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/autogen/lib/python3.10/site-packages/autogen/agentchat/contrib/multimodal_conversable_agent.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     38\u001b[0m     name,\n\u001b[1;32m     39\u001b[0m     system_message,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_system_message(system_message)\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_termination_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     47\u001b[0m     is_termination_msg\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m is_termination_msg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     \u001b[39melse\u001b[39;00m (\u001b[39mlambda\u001b[39;00m x: \u001b[39many\u001b[39m([item[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTERMINATE\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m item[\u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     50\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=\"Generate an image of a baby sheep.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
